#!/usr/bin/env python3
from __future__ import annotations

"""
–†–∞—Å–ø—Ä–µ–¥–µ–ª—è–µ—Ç –ª–æ—Ç—ã –∏–∑ —Ä–µ–µ—Å—Ç—Ä–∞ –∞—É–∫—Ü–∏–æ–Ω–∞ –ø–æ –ø–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è–º —Å —É—á–µ—Ç–æ–º –ø—Ä–æ–¥–∞–∂ –∏ —Ç–µ–∫—É—â–∏—Ö –æ—Å—Ç–∞—Ç–∫–æ–≤.

–õ–æ–≥–∏–∫–∞:
1. –°–∫–æ—Ä–æ—Å—Ç—å –ø—Ä–æ–¥–∞–∂ (—à—Ç./–Ω–µ–¥–µ–ª—è) –±–µ—Ä–µ—Ç—Å—è –∏–∑ —Ñ–∞–π–ª–∞ —Ç–∞–±–ª–∏—Ü—ã –ø—Ä–æ–¥–∞–∂, –≥–¥–µ –µ—Å—Ç—å –∫–æ–ª–æ–Ω–∫–∞ –ø–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è.
2. –ü–æ–∫—Ä—ã—Ç–∏–µ = –æ—Å—Ç–∞—Ç–æ–∫ / —Å–∫–æ—Ä–æ—Å—Ç—å. –ß–µ–º –º–µ–Ω—å—à–µ –ø–æ–∫—Ä—ã—Ç–∏–µ, —Ç–µ–º –ø—Ä–∏–≤–ª–µ–∫–∞—Ç–µ–ª—å–Ω–µ–µ –ø–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–ª—è –æ—Ç–≥—Ä—É–∑–∫–∏.
3. –î–ª—è –∫–∞–∂–¥–æ–≥–æ –∞—Ä—Ç–∏–∫—É–ª–∞ –∏–∑ —Ä–µ–µ—Å—Ç—Ä–∞ –∞—É–∫—Ü–∏–æ–Ω–∞ –ª–æ—Ç—ã —Ä–∞–∑–Ω–æ—Å—è—Ç—Å—è –ø–æ –ø–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è–º —Å –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–º –ø–æ–∫—Ä—ã—Ç–∏–µ–º,
   –ø—Ä–∏ —Ä–∞–≤–µ–Ω—Å—Ç–≤–µ ‚Äî –ø–æ –±–æ–ª—å—à–µ–π —Å–∫–æ—Ä–æ—Å—Ç–∏ –ø—Ä–æ–¥–∞–∂. –ü—Ä–∏ –∫–∞–∂–¥–æ–π –≤—ã–¥–∞—á–µ –ø–æ–∫—Ä—ã—Ç–∏–µ –ø–µ—Ä–µ—Å—á–∏—Ç—ã–≤–∞–µ—Ç—Å—è.
4. –ï—Å–ª–∏ –ø–æ –∞—Ä—Ç–∏–∫—É–ª—É –Ω–µ—Ç –Ω–∏ –æ—Å—Ç–∞—Ç–∫–æ–≤, –Ω–∏ –ø—Ä–æ–¥–∞–∂ ‚Äî –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤ –ø–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è —Å –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –æ–±—â–µ–π —Å–∫–æ—Ä–æ—Å—Ç—å—é –ø—Ä–æ–¥–∞–∂.
"""

import argparse
import logging
import math
import re
from dataclasses import dataclass
from pathlib import Path
from typing import Dict, List, Optional
from datetime import datetime

import pandas as pd

logger = logging.getLogger(__name__)

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –≤ —Ñ–∞–π–ª
BASE_DIR = Path(__file__).resolve().parents[2]
LOG_DIR = BASE_DIR / "logs"
LOG_DIR.mkdir(exist_ok=True)

def setup_logging():
    """–ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç –¥–µ—Ç–∞–ª—å–Ω–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –≤ —Ñ–∞–π–ª –∏ –∫–æ–Ω—Å–æ–ª—å."""
    # –°–æ–∑–¥–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω–æ–µ –∏–º—è —Ñ–∞–π–ª–∞ —Å timestamp
    log_file = LOG_DIR / f"allocation_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log"
    
    # –°–æ–∑–¥–∞–µ–º —Ñ–æ—Ä–º–∞—Ç—Ç–µ—Ä
    formatter = logging.Formatter(
        '%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S'
    )
    
    # File handler
    file_handler = logging.FileHandler(log_file, encoding='utf-8')
    file_handler.setLevel(logging.DEBUG)
    file_handler.setFormatter(formatter)
    
    # Console handler
    console_handler = logging.StreamHandler()
    console_handler.setLevel(logging.INFO)
    console_handler.setFormatter(formatter)
    
    # –û—á–∏—â–∞–µ–º —Å—Ç–∞—Ä—ã–µ handlers —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏—è
    logger.handlers.clear()
    
    # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º logger
    logger.setLevel(logging.DEBUG)
    logger.addHandler(file_handler)
    logger.addHandler(console_handler)
    
    logger.info(f"üìù –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–æ. –§–∞–π–ª: {log_file}")
    return log_file


def normalize_sku(value: object, pad_to: int = 11) -> Optional[str]:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∞—Ä—Ç–∏–∫—É–ª –∫–∞–∫ —Å—Ç—Ä–æ–∫—É —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –≤–µ–¥—É—â–∏—Ö –Ω—É–ª–µ–π."""
    if pd.isna(value):
        return None
    text = str(value).strip()
    if not text:
        return None

    digits = "".join(ch for ch in text if ch.isdigit())
    if digits:
        return digits.zfill(pad_to)
    return text


def normalize_name(value: object) -> str:
    """–ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç –Ω–∞–∑–≤–∞–Ω–∏—è –ø–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏–π/—Ä–µ–≥–∏–æ–Ω–æ–≤: lowercase + —É–±–∏—Ä–∞–µ—Ç –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã."""
    if pd.isna(value):
        return ""
    text = str(value).strip().lower()
    # –ó–∞–º–µ–Ω—è–µ–º –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –ø—Ä–æ–±–µ–ª—ã –Ω–∞ –æ–¥–∏–Ω
    text = re.sub(r'\s+', ' ', text)
    return text


def load_sales_table(path: Path) -> pd.DataFrame:
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç —Ñ–∞–π–ª "–¢–∞–±–ª–∏—á–Ω–∞—è_—á–∞—Å—Ç—å_–ü—Ä–æ–¥–∞–∂–∏_—Ä–∞—Å–ø—Ä–æ–¥–∞–∂–∞_0109_311225.xlsx".
    –ù—É–∂–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –ø–æ –ø–æ–∑–∏—Ü–∏—è–º (0-–±–∞–∑–æ–≤–∞—è –Ω—É–º–µ—Ä–∞—Ü–∏—è):
        0: –†–µ–≥–∏–æ–Ω –¥–ª—è —ç–∫–æ–Ω–æ–º–∏—Å—Ç–æ–≤
        4: –ü–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ
        7: –î–∞—Ç–∞
        11: –ó–∞–ª–æ–≥–æ–≤—ã–π –±–∏–ª–µ—Ç; –°–∫—É–ø–æ—á–Ω–∞—è –∫–≤–∏—Ç–∞–Ω—Ü–∏—è (–∞—Ä—Ç–∏–∫—É–ª)
        12: –†–µ–≥–∏—Å—Ç—Ä–∞—Ç–æ—Ä.–ù–æ–º–µ—Ä (–∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏)
        18: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ
    """
    df = pd.read_excel(
        path,
        header=None,
        usecols=[0, 4, 7, 8, 11, 12, 18, 19, 20],
        skiprows=10,  # –ø—Ä–æ–ø—É—Å–∫–∞–µ–º —Å–ª—É–∂–µ–±–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏ –∏ –∑–∞–≥–æ–ª–æ–≤–∫–∏
    )
    df.columns = [
        "region",
        "department",
        "sale_date",
        "category",
        "sku",
        "doc_number",
        "qty",
        "sale_amount",
        "loan_amount",
    ]

    df["sale_date"] = pd.to_datetime(df["sale_date"], errors="coerce", dayfirst=True)
    df["sku"] = df["sku"].apply(normalize_sku)
    df = df.dropna(subset=["sale_date", "sku"])

    df["department"] = df["department"].apply(normalize_name)
    df["region"] = df["region"].apply(normalize_name)
    df["category"] = df["category"].astype(str).str.strip().replace({"nan": None, "None": None})
    df["qty"] = pd.to_numeric(df["qty"], errors="coerce").fillna(1).astype(float)
    df["sale_amount"] = pd.to_numeric(df["sale_amount"], errors="coerce").fillna(0.0)
    df["loan_amount"] = pd.to_numeric(df["loan_amount"], errors="coerce").fillna(0.0)

    # –í –∏—Å—Ö–æ–¥–Ω–∏–∫–µ –∫–∞–∂–¥–∞—è –ø—Ä–æ–¥–∞–∂–∞ —á–∞—Å—Ç–æ –ø—Ä–æ–¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∞ (—Å—Ç—Ä–æ–∫–∞ —Å —Ç–µ–ª–µ—Ñ–æ–Ω–æ–º –∏ –±–µ–∑).
    df = df.drop_duplicates(subset=["department", "sku", "sale_date", "doc_number"])
    return df


def compute_velocity(sales: pd.DataFrame) -> tuple[pd.DataFrame, pd.DataFrame, int]:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (—Å–∫–æ—Ä–æ—Å—Ç—å –ø–æ SKU+–ø–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ, —Å–∫–æ—Ä–æ—Å—Ç—å –ø–æ –ø–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏—é, –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –æ–∫–Ω–∞ –≤ –Ω–µ–¥–µ–ª—è—Ö)."""
    if sales.empty:
        empty_sku = pd.DataFrame(columns=["sku", "department", "region", "weekly_velocity"])
        empty_dep = pd.DataFrame(columns=["department", "region", "weekly_velocity"])
        return empty_sku, empty_dep, 1

    date_span_days = (sales["sale_date"].max() - sales["sale_date"].min()).days
    
    # –í–∞–ª–∏–¥–∞—Ü–∏—è –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–≥–æ –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ –æ–∫–Ω–∞
    MIN_WINDOW_DAYS = 7
    if date_span_days < MIN_WINDOW_DAYS:
        logger.warning(
            f"‚ö†Ô∏è –î–∞–Ω–Ω—ã–µ –ø—Ä–æ–¥–∞–∂ –æ—Ö–≤–∞—Ç—ã–≤–∞—é—Ç —Ç–æ–ª—å–∫–æ {date_span_days} –¥–Ω–µ–π (–º–µ–Ω—å—à–µ {MIN_WINDOW_DAYS}). "
            "–°–∫–æ—Ä–æ—Å—Ç—å –ø—Ä–æ–¥–∞–∂ –º–æ–∂–µ—Ç –±—ã—Ç—å –Ω–µ—Ç–æ—á–Ω–æ–π. –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –¥–∞–Ω–Ω—ã–µ –º–∏–Ω–∏–º—É–º –∑–∞ –Ω–µ–¥–µ–ª—é."
        )
    
    weeks_span = max(1, math.ceil(date_span_days / 7))

    sku_velocity = (
        sales.groupby(["sku", "department", "region"])["qty"].sum() / weeks_span
    ).reset_index()
    sku_velocity = sku_velocity.rename(columns={"qty": "weekly_velocity"})

    dept_velocity = (
        sales.groupby(["department", "region"])["qty"].sum() / weeks_span
    ).reset_index()
    dept_velocity = dept_velocity.rename(columns={"qty": "weekly_velocity"})

    return sku_velocity, dept_velocity, weeks_span


def load_stock(path: Path) -> pd.DataFrame:
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç —Ñ–∞–π–ª –æ—Å—Ç–∞—Ç–∫–æ–≤.
    –ù—É–∂–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏ (0-–±–∞–∑–æ–≤–∞—è –Ω—É–º–µ—Ä–∞—Ü–∏—è):
        0: –†–µ–≥–∏–æ–Ω
        2: –ü–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ
        5: –ó–∞–ª–æ–≥–æ–≤—ã–π –±–∏–ª–µ—Ç (–∞—Ä—Ç–∏–∫—É–ª)
        9: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ, —à—Ç
    """
    df = pd.read_excel(path, header=None, usecols=[0, 2, 5, 7, 9], skiprows=10)
    df.columns = ["region", "department", "sku", "category", "stock_qty"]

    df["sku"] = df["sku"].apply(normalize_sku)
    df = df.dropna(subset=["sku"])

    df["department"] = df["department"].apply(normalize_name)
    df["region"] = df["region"].apply(normalize_name)
    df["category"] = df["category"].astype(str).str.strip().replace({"nan": None, "None": None})
    df["stock_qty"] = pd.to_numeric(df["stock_qty"], errors="coerce").fillna(0)

    # –°—É–º–º–∏—Ä—É–µ–º, –µ—Å–ª–∏ –∞—Ä—Ç–∏–∫—É–ª –ø–æ–≤—Ç–æ—Ä—è–µ—Ç—Å—è –≤ –æ–¥–Ω–æ–º –ø–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏–∏.
    df = df.groupby(["sku", "department", "region", "category"], as_index=False)["stock_qty"].sum()
    return df


def load_auction(path: Path, sku_column: Optional[str] = None) -> tuple[Dict[str, int], Dict[str, Dict[str, object]]]:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (—Å—á–µ—Ç—á–∏–∫ SKU, –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –ø–æ SKU)."""
    df = pd.read_excel(path)
    candidates = [
        sku_column,
        "3.–ó–∞–ª–æ–≥–æ–≤—ã–π –±–∏–ª–µ—Ç (–∑–∞–ø–æ–ª–Ω—è–µ—Ç—Å—è —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–º –æ—Ç–¥–µ–ª–∞ –ù–Æ–ó)",
        "–ê—Ä—Ç–∏–∫—É–ª",
    ]
    sku_col = next((c for c in candidates if c and c in df.columns), None)
    if sku_col is None:
        raise ValueError("–ù–µ –Ω–∞—à–µ–ª –∫–æ–ª–æ–Ω–∫—É —Å –∞—Ä—Ç–∏–∫—É–ª–æ–º –≤ —Ä–µ–µ—Å—Ç—Ä–µ –∞—É–∫—Ü–∏–æ–Ω–∞")

    df["sku"] = df[sku_col].apply(normalize_sku)
    df["category"] = df.get("4.–í–∏–¥ –ø—Ä–µ–¥–º–µ—Ç–∞ (–∑–∞–ø–æ–ª–Ω—è–µ—Ç—Å—è —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–º –æ—Ç–¥–µ–ª–∞ –ù–Æ–ó)", pd.Series(dtype=object))
    df["description"] = df.get("5.–û–ø–∏—Å–∞–Ω–∏–µ (–∑–∞–ø–æ–ª–Ω—è–µ—Ç—Å—è —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–º –æ—Ç–¥–µ–ª–∞ –ù–Æ–ó)", pd.Series(dtype=object))
    df["loan"] = pd.to_numeric(df.get("6.–°—Å—É–¥–∞ (–∑–∞–ø–æ–ª–Ω—è–µ—Ç—Å—è —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–º –æ—Ç–¥–µ–ª–∞ –ù–Æ–ó)", pd.Series(dtype=object)), errors="coerce")
    df["retail_price"] = pd.to_numeric(df.get("7.–†–æ–∑–Ω–∏—á–Ω–∞—è —Ü–µ–Ω–∞ (–∑–∞–ø–æ–ª–Ω—è–µ—Ç—Å—è —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–º –æ—Ç–¥–µ–ª–∞ –ù–Æ–ó)", pd.Series(dtype=object)), errors="coerce")
    df["recommended_price"] = pd.to_numeric(df.get("11.–†–µ–∫–æ–º–µ–Ω–¥—É–µ–º–∞—è —Ä–æ–∑–Ω–∏—á–Ω–∞—è —Ü–µ–Ω–∞ (–∑–∞–ø–æ–Ω—è–µ—Ç—Å—è —Å—Ç–∞—Ä—à–∏–º —Ç–æ–≤–∞—Ä–æ–≤–µ–¥–æ–º-–ø—Ä–∏–µ–º—â–∏–∫–æ–º)", pd.Series(dtype=object)), errors="coerce")

    df["category"] = df["category"].astype(str).str.strip()
    df["description"] = df["description"].astype(str).str.strip()

    counts = df["sku"].dropna().value_counts().to_dict()
    if not counts:
        raise ValueError("–í —Ä–µ–µ—Å—Ç—Ä–µ –∞—É–∫—Ü–∏–æ–Ω–∞ –Ω–µ—Ç –∞—Ä—Ç–∏–∫—É–ª–æ–≤ –¥–ª—è —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è")

    meta: Dict[str, Dict[str, object]] = {}
    for _, row in df.dropna(subset=["sku"]).iterrows():
        sku = row["sku"]
        if sku not in meta:
            meta[sku] = {
                "category": row.get("category"),
                "description": row.get("description"),  # –ù–û–í–û–ï
                "loan": row.get("loan"),
                "retail_price": row.get("retail_price"),
                "recommended_price": row.get("recommended_price"),
            }
    return counts, meta


def build_coverage(stock: pd.DataFrame, velocity: pd.DataFrame) -> pd.DataFrame:
    """
    –°–æ–∑–¥–∞–µ—Ç —Ç–∞–±–ª–∏—Ü—É –ø–æ–∫—Ä—ã—Ç–∏—è –ø–æ –∫–∞–∂–¥–æ–º—É (sku, –ø–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ):
    - stock_qty: —Ç–µ–∫—É—â–∏–π –æ—Å—Ç–∞—Ç–æ–∫
    - weekly_velocity: –ø—Ä–æ–¥–∞–∂–∏ –≤ –Ω–µ–¥–µ–ª—é
    - coverage_weeks: –Ω–µ–¥–µ–ª—å –ø–æ–∫—Ä—ã—Ç–∏—è –Ω–∞ —Ç–µ–∫—É—â–µ–º —Å—Ç–æ–∫–µ
    """
    coverage = pd.merge(
        stock,
        velocity,
        on=["sku", "department"],
        how="outer",
        suffixes=("_stock", "_velocity"),
    )

    coverage["region"] = coverage["region_stock"].fillna(coverage["region_velocity"])
    coverage["category"] = coverage["category"]
    coverage["stock_qty"] = coverage["stock_qty"].fillna(0)
    coverage["weekly_velocity"] = coverage["weekly_velocity"].fillna(0)

    coverage["coverage_weeks"] = coverage.apply(
        lambda row: math.inf
        if row["weekly_velocity"] <= 0
        else row["stock_qty"] / row["weekly_velocity"],
        axis=1,
    )
    coverage["stock_qty"] = coverage["stock_qty"].astype(float)
    coverage["weekly_velocity"] = coverage["weekly_velocity"].astype(float)
    coverage["coverage_weeks"] = coverage["coverage_weeks"].astype(float)

    return coverage[["sku", "department", "region", "category", "stock_qty", "weekly_velocity", "coverage_weeks"]]


@dataclass
class AllocationConfig:
    """–ù–∞—Å—Ç—Ä–æ–π–∫–∏ –∞–ª–≥–æ—Ä–∏—Ç–º–∞ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è."""

    target_coverage_weeks: float = 4.0  # —Ü–µ–ª–µ–≤–æ–µ –ø–æ–∫—Ä—ã—Ç–∏–µ –ø–æ –∑–∞–ø–∞—Å–∞–º
    coverage_weight: float = 0.2  # –Ω–µ–±–æ–ª—å—à–æ–π –≤–µ—Å –¥–µ—Ñ–∏—Ü–∏—Ç–∞ (—É—á–∏—Ç—ã–≤–∞–µ–º, –Ω–æ –Ω–µ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç)
    velocity_weight: float = 10.0  # üöÄ –ì–õ–ê–í–ù–´–ô –ü–†–ò–û–†–ò–¢–ï–¢: –º–∞–∫—Å–∏–º–∏–∑–∏—Ä—É–µ–º —Å–∫–æ—Ä–æ—Å—Ç—å –ø—Ä–æ–¥–∞–∂!
    fairness_penalty: float = 0.05  # ‚öñÔ∏è –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —à—Ç—Ä–∞—Ñ (–Ω–µ —Å—Ç—Ä–µ–º–∏–º—Å—è –∫ —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ—Å—Ç–∏)
    max_department_percentage: float = None  # ‚ùå –£–ë–†–ê–õ–ò –∂–µ—Å—Ç–∫–∏–π –ª–∏–º–∏—Ç –Ω–∞ –ø–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ
    max_add_per_department: Optional[int] = None  # –Ω–µ—Ç –ª–∏–º–∏—Ç–∞ –≤—ã–¥–∞—á–∏ –ø–æ –æ–¥–Ω–æ–º—É SKU
    prob_target_days: int = 30  # –≥–æ—Ä–∏–∑–æ–Ω—Ç –ø—Ä–æ–≥–Ω–æ–∑–∞ –¥–ª—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –ø—Ä–æ–¥–∞–∂–∏
    velocity_prior: float = 0.2  # —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏–µ —Å–∫–æ—Ä–æ—Å—Ç–∏ –¥–ª—è —Ä–µ–¥–∫–∏—Ö SKU
    alpha_cat_velocity: float = 0.8  # –≤–µ—Å –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
    alpha_dept_velocity: float = 0.2  # –≤–µ—Å –æ–±—â–µ–π —Å–∫–æ—Ä–æ—Å—Ç–∏ –ø–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è
    category_diversity_bonus: float = 1.0  # –±–æ–Ω—É—Å –∑–∞ –Ω–æ–≤—É—é –∫–∞—Ç–µ–≥–æ—Ä–∏—é
    
    # üÜï –£–°–ò–õ–ï–ù–ù–´–ô –ö–û–ù–¢–†–û–õ–¨ –ê–°–°–û–†–¢–ò–ú–ï–ù–¢–ê (–∏–∑–±–µ–≥–∞–µ–º —Å–∫–æ–ø–ª–µ–Ω–∏—è –æ–¥–∏–Ω–∞–∫–æ–≤—ã—Ö —Ç–æ–≤–∞—Ä–æ–≤)
    category_congestion_penalty: float = 15.0  # üî• –°–ò–õ–¨–ù–´–ô —à—Ç—Ä–∞—Ñ –∑–∞ —Å–∫–æ–ø–ª–µ–Ω–∏–µ –æ–¥–Ω–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
    empty_category_bonus: float = 80.0  # üåü –û–ì–†–û–ú–ù–´–ô –±–æ–Ω—É—Å –∑–∞ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ –∞—Å—Å–æ—Ä—Ç–∏–º–µ–Ω—Ç–∞
    category_threshold: int = 10  # –ø–æ—Ä–æ–≥: –µ—Å–ª–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –±–æ–ª—å—à–µ N —à—Ç—É–∫, —É—Å–∏–ª–∏–≤–∞–µ–º —à—Ç—Ä–∞—Ñ
    category_overload_multiplier: float = 2.5  # –º–Ω–æ–∂–∏—Ç–µ–ª—å —à—Ç—Ä–∞—Ñ–∞ –ø–æ—Å–ª–µ –ø—Ä–µ–≤—ã—à–µ–Ω–∏—è –ø–æ—Ä–æ–≥–∞
    gashek_dampener: float = 0.3  # –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –¥–ª—è –ì–∞—à–µ–∫–∞ (—É–º–Ω–æ–∂–∞–µ–º —Å–∫–æ—Ä–æ—Å—Ç—å –Ω–∞ 0.3)
    
    min_categories_per_department: int = 5  # —Ü–µ–ª–µ–≤–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–∞—Ç–µ–≥–æ—Ä–∏–π
    margin_weight: float = 0.15  # –≤–µ—Å –æ–∂–∏–¥–∞–µ–º–æ–π –º–∞—Ä–∂–∏ (—á—É—Ç—å —É—Å–∏–ª–µ–Ω)
    min_candidates: int = 5  # –º–∏–Ω–∏–º—É–º –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –¥–ª—è —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è


def predict_sell_probability(weekly_velocity: float, target_days: int, velocity_prior: float) -> float:
    """
    –û—Ü–µ–Ω–∏–≤–∞–µ—Ç –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –ø—Ä–æ–¥–∞–∂–∏ –∑–∞ target_days –ø—Ä–∏ —ç–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–æ–º —Å–ø—Ä–æ—Å–µ.
    weekly_velocity ‚Äî —Å–∫–æ—Ä–æ—Å—Ç—å (—à—Ç./–Ω–µ–¥–µ–ª—è). –î–æ–±–∞–≤–ª—è–µ–º prior, —á—Ç–æ–±—ã –Ω–µ –±—ã–ª–æ –Ω—É–ª–µ–π.
    """
    lam = max(weekly_velocity + velocity_prior, 0.0) / 7  # –∏–Ω—Ç–µ–Ω—Å–∏–≤–Ω–æ—Å—Ç—å –≤ –¥–µ–Ω—å
    if lam <= 0:
        return 0.0
    prob = 1 - math.exp(-lam * target_days)
    return max(0.0, min(1.0, prob))


def allocate_sku(
    sku: str,
    qty: int,
    coverage: pd.DataFrame,
    dept_velocity: pd.DataFrame,
    cat_velocity: Dict[tuple, float],
    dept_velocity_map: Dict[str, float],
    auction_meta: Dict[str, Dict[str, object]],
    allocations: List[Dict],  # –ù–û–í–û–ï: –ø–µ—Ä–µ–¥–∞–µ–º —Å–ø–∏—Å–æ–∫ –¥–ª—è –∑–∞–ø–æ–ª–Ω–µ–Ω–∏—è
    dept_cat_qty_map: Dict[str, Dict[str, int]], # –ù–û–í–û–ï: –∫–∞—Ä—Ç–∞ –∫–æ–ª–∏—á–µ—Å—Ç–≤
    cfg: AllocationConfig,
    stock: pd.DataFrame = None,  # –ù–û–í–û–ï: –¥–ª—è —É—á–µ—Ç–∞ –æ–±—â–∏—Ö –æ—Å—Ç–∞—Ç–∫–æ–≤
    global_dept_load: Dict[str, int] = None, # –ù–û–í–û–ï
    max_per_dept_global: int = None # –ù–û–í–û–ï
) -> List[Dict[str, object]]:
    """
    –†–∞—Å–ø—Ä–µ–¥–µ–ª—è–µ—Ç qty —à—Ç—É–∫ –∞—Ä—Ç–∏–∫—É–ª–∞ sku –ø–æ –ø–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è–º.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —Å—Ç—Ä–æ–∫ –¥–ª—è –∏—Ç–æ–≥–æ–≤–æ–π —Ç–∞–±–ª–∏—Ü—ã.
    """
    logger.info(f"\n{'='*80}")
    logger.info(f"üéØ –ù–∞—á–∏–Ω–∞–µ–º —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ SKU: {sku}, –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ: {qty} —à—Ç")
    
    pool = coverage[coverage["sku"] == sku].copy()

    if pool.empty:
        logger.debug(f"  ‚ö†Ô∏è –ù–µ—Ç –∏—Å—Ç–æ—Ä–∏–∏ –ø–æ SKU {sku}, –∏—Å–ø–æ–ª—å–∑—É–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ + –æ–±—â–∏–µ –æ—Å—Ç–∞—Ç–∫–∏")
        # –ù–µ—Ç –∏—Å—Ç–æ—Ä–∏–∏ –ø–æ SKU ‚Äî –∏—Å–ø–æ–ª—å–∑—É–µ–º –∫–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –ø–æ–¥—Ö–æ–¥
        
        # –ü–æ–ª—É—á–∞–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏—é —Ç–æ–≤–∞—Ä–∞
        cat = auction_meta.get(sku, {}).get("category")
        
        # –ù–∞—á–∏–Ω–∞–µ–º —Å –ø–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏–π
        pool = dept_velocity.copy()
        pool["sku"] = sku
        pool["stock_qty"] = 0
        pool["category"] = cat
        
        # –î–æ–±–∞–≤–ª—è–µ–º –æ–±—â–∏–π –æ—Å—Ç–∞—Ç–æ–∫ –ø–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω)
        if stock is not None and not stock.empty:
            dept_total_stock = stock.groupby("department")["stock_qty"].sum().reset_index()
            dept_total_stock.columns = ["department", "total_stock"]
            pool = pool.merge(dept_total_stock, on="department", how="left")
            pool["total_stock"] = pool["total_stock"].fillna(0)
            
            # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –æ–±—â–µ–µ –ø–æ–∫—Ä—ã—Ç–∏–µ –ø–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è
            pool["dept_coverage"] = pool.apply(
                lambda row: math.inf if row["weekly_velocity"] <= 0
                else row["total_stock"] / row["weekly_velocity"],
                axis=1
            )
            logger.debug(f"  üìä –î–æ–±–∞–≤–ª–µ–Ω—ã –æ–±—â–∏–µ –æ—Å—Ç–∞—Ç–∫–∏ –ø–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏–π")
        else:
            pool["total_stock"] = 0
            pool["dept_coverage"] = math.inf
        
        pool["coverage_weeks"] = pool.apply(
            lambda row: math.inf if row["weekly_velocity"] <= 0 else 0,
            axis=1,
        )

    # –ï—Å–ª–∏ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –º–∞–ª–æ, –¥–æ–±–∞–≤–∏–º —Ç–æ–ø –ø–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏–π –ø–æ —Å–∫–æ—Ä–æ—Å—Ç–∏.
    if len(pool) < cfg.min_candidates:
        logger.debug(f"  üìä –ö–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –º–∞–ª–æ ({len(pool)}), –¥–æ–±–∞–≤–ª—è–µ–º —Ç–æ–ø –ø–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏–π")
        existing_depts = set(pool["department"].tolist())
        extra = dept_velocity[~dept_velocity["department"].isin(existing_depts)].copy()
        if not extra.empty:
            extra = extra.nlargest(cfg.min_candidates, "weekly_velocity")
            extra["sku"] = sku
            extra["stock_qty"] = 0
            extra["coverage_weeks"] = extra.apply(
                lambda row: math.inf if row["weekly_velocity"] <= 0 else 0,
                axis=1,
            )
            extra["category"] = auction_meta.get(sku, {}).get("category")
            pool = pd.concat([pool, extra], ignore_index=True)

    pool["stock_qty"] = pool["stock_qty"].astype(float)
    pool["weekly_velocity"] = pool["weekly_velocity"].astype(float)
    pool["coverage_weeks"] = pool["coverage_weeks"].astype(float)
    pool["category"] = pool.get("category", pd.Series(dtype=object))

    if pool.empty:
        logger.warning(f"  ‚ùå –°–æ–≤—Å–µ–º –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è SKU {sku} ‚Äî –Ω–µ –º–æ–∂–µ–º —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–∏—Ç—å")
        return []

    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–µ–¥–∞–Ω–Ω—ã–π –≥–ª–æ–±–∞–ª—å–Ω—ã–π —Å—á–µ—Ç—á–∏–∫ –∏–ª–∏ —Å–æ–∑–¥–∞–µ–º –ª–æ–∫–∞–ª—å–Ω—ã–π (–µ—Å–ª–∏ –Ω–µ –ø–µ—Ä–µ–¥–∞–Ω)
    if global_dept_load is None:
        global_dept_load = {}

    remaining = int(qty) # –í–û–°–°–¢–ê–ù–û–í–õ–ï–ù–û
    
    logger.info(f"  üì¶ –î–æ—Å—Ç—É–ø–Ω–æ –ø–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏–π-–∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤: {len(pool)}")
    logger.debug(f"  –ö–∞–Ω–¥–∏–¥–∞—Ç—ã: {pool[['department', 'stock_qty', 'weekly_velocity', 'coverage_weeks']].to_string()}")

    iteration = 0
    for remaining_to_allocate in range(qty, 0, -1):
        if pool.empty:
            logger.warning(f"  ‚ö†Ô∏è –ó–∞–∫–æ–Ω—á–∏–ª–∏—Å—å –∫–∞–Ω–¥–∏–¥–∞—Ç—ã –Ω–∞ –æ—Ç–ø—Ä–∞–≤–∫—É, –æ—Å—Ç–∞–ª–æ—Å—å {remaining_to_allocate} —à—Ç.")
            break

        def score_row(row):
            dept = row["department"]
            
            cat = row.get("category")
            if pd.isna(cat):
                cat = str(auction_meta.get(sku, {}).get("category", ""))
            cat = str(cat).strip()

            base_vel = row["weekly_velocity"] if pd.notna(row["weekly_velocity"]) else 0.0
            
            # üìâ –î–ï–ú–ü–§–ï–† –î–õ–Ø –ì–ê–®–ï–ö–ê (‚Ññ544)
            # –ï—Å–ª–∏ —ç—Ç–æ –ì–∞—à–µ–∫–∞, –º—ã –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ –∑–∞–Ω–∏–∂–∞–µ–º —Å–∫–æ—Ä–æ—Å—Ç—å, —Ç.–∫. —Ç–∞–º –ø–µ—Ä–µ–∫—É–ø—ã
            if "544" in dept or "–≥–∞—à–µ–∫–∞" in dept.lower():
                base_vel *= cfg.gashek_dampener
                # logger.debug(f"    üìâ {dept}: —Å–∫–æ—Ä–æ—Å—Ç—å –∑–∞–Ω–∏–∂–µ–Ω–∞ (–ì–∞—à–µ–∫–∞) –¥–æ {base_vel:.2f}")

            blend_vel = base_vel
            
            # –î–ª—è —Ç–æ–≤–∞—Ä–æ–≤ —Å –∫–∞—Ç–µ–≥–æ—Ä–∏–µ–π - —É—Å–∏–ª–µ–Ω–Ω—ã–π —É—á–µ—Ç –∫–∞—Ç–µ–≥–æ—Ä–∏–π–Ω–æ–π —Å–∫–æ—Ä–æ—Å—Ç–∏
            if cat:
                cat_vel = cat_velocity.get((cat, dept), 0)
                # –¢–æ–∂–µ –¥–µ–º–ø—Ñ–∏—Ä—É–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏–π–Ω—É—é —Å–∫–æ—Ä–æ—Å—Ç—å –¥–ª—è –ì–∞—à–µ–∫–∞
                if "544" in dept or "–≥–∞—à–µ–∫–∞" in dept.lower():
                    cat_vel *= cfg.gashek_dampener
                
                blend_vel += cfg.alpha_cat_velocity * cat_vel
            
            blend_vel += cfg.alpha_dept_velocity * dept_velocity_map.get(dept, 0)

            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–π gap (—Ç–æ–ª—å–∫–æ –¥–µ—Ñ–∏—Ü–∏—Ç —É—á–∏—Ç—ã–≤–∞–µ—Ç—Å—è)
            coverage_val = row["coverage_weeks"]
            if math.isinf(coverage_val):
                coverage_val = 1000.0
            coverage_gap = max(0, cfg.target_coverage_weeks - coverage_val)
            
            # Fairness penalty (—à—Ç—Ä–∞—Ñ –∑–∞ –ø–µ—Ä–µ–≥—Ä—É–∑–∫—É)
            fairness = global_dept_load.get(dept, 0) ** 2.0

            meta = auction_meta.get(sku, {})
            loan = meta.get("loan") or 0
            price = meta.get("recommended_price") or meta.get("retail_price") or 0
            margin = max(price - loan, 0) if pd.notna(loan) and pd.notna(price) else 0

            # üÜï –ê–°–°–û–†–¢–ò–ú–ï–ù–¢–ù–ê–Ø –õ–û–ì–ò–ö–ê –° –ü–†–û–ì–†–ï–°–°–ò–í–ù–´–ú –®–¢–†–ê–§–û–ú
            assortment_score = 0.0
            if cat:
                # –°–∫–æ–ª—å–∫–æ —É–∂–µ –µ—Å—Ç—å —Ç–∞–∫–∏—Ö –ø—Ä–µ–¥–º–µ—Ç–æ–≤ (–æ—Å—Ç–∞—Ç–∫–∏ + —Ç–æ —á—Ç–æ –≤—ã–¥–∞–ª–∏ —Å–µ–π—á–∞—Å)
                current_qty = dept_cat_qty_map.get(dept, {}).get(cat, 0)
                
                if current_qty == 0:
                    # üî• –û–ì–†–û–ú–ù–´–ô –ë–û–ù–£–° –ó–ê –ü–£–°–¢–£–Æ –ö–ê–¢–ï–ì–û–†–ò–Æ (—Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ –∞—Å—Å–æ—Ä—Ç–∏–º–µ–Ω—Ç–∞)
                    assortment_score += cfg.empty_category_bonus
                    # logger.debug(f"    ‚ú® {dept}: –Ω–µ—Ç –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ '{cat}' -> –±–æ–Ω—É—Å +{cfg.empty_category_bonus}")
                else:
                    # ‚ö†Ô∏è –ü–†–û–ì–†–ï–°–°–ò–í–ù–´–ô –®–¢–†–ê–§ –∑–∞ —Å–∫—É—á–µ–Ω–Ω–æ—Å—Ç—å
                    # –ë–∞–∑–æ–≤—ã–π —à—Ç—Ä–∞—Ñ
                    penalty = current_qty * cfg.category_congestion_penalty
                    
                    # üî• –£–°–ò–õ–ï–ù–ù–´–ô —à—Ç—Ä–∞—Ñ –µ—Å–ª–∏ –ø—Ä–µ–≤—ã—à–µ–Ω –ø–æ—Ä–æ–≥ (–Ω–∞–ø—Ä–∏–º–µ—Ä, >10 —Ç–µ–ª–µ—Ñ–æ–Ω–æ–≤)
                    if current_qty >= cfg.category_threshold:
                        overload = current_qty - cfg.category_threshold
                        penalty += overload * cfg.category_congestion_penalty * cfg.category_overload_multiplier
                        # logger.debug(f"    üö® {dept}: –ü–ï–†–ï–ì–†–£–ó '{cat}' ({current_qty} —à—Ç) -> —É—Å–∏–ª–µ–Ω–Ω—ã–π —à—Ç—Ä–∞—Ñ -{penalty:.1f}")
                    
                    assortment_score -= penalty
                    # logger.debug(f"    ‚ö†Ô∏è {dept}: —É–∂–µ –µ—Å—Ç—å {current_qty} —à—Ç '{cat}' -> —à—Ç—Ä–∞—Ñ -{penalty:.1f}")

            score = (
                cfg.coverage_weight * coverage_gap
                + cfg.velocity_weight * blend_vel
                + cfg.margin_weight * margin
                + assortment_score # –î–æ–±–∞–≤–ª—è–µ–º –∞—Å—Å–æ—Ä—Ç–∏–º–µ–Ω—Ç–Ω—ã–π –≤–∫–ª–∞–¥
                - cfg.fairness_penalty * fairness
            )
            # –ó–∞—â–∏—Ç–∞ –æ—Ç NaN
            if not math.isfinite(score):
                logger.warning(f"    ‚ö†Ô∏è NaN score –¥–ª—è {dept}: coverage_gap={coverage_gap}, blend_vel={blend_vel}, margin={margin}")
                score = blend_vel  # fallback –Ω–∞ velocity
            
            return score

        # –ü—Ä–∏–º–µ–Ω—è–µ–º scoring –∫–æ –≤—Å–µ–º –∫–∞–Ω–¥–∏–¥–∞—Ç–∞–º
        pool["score"] = pool.apply(score_row, axis=1)
        
        # –§–∏–ª—å—Ç—Ä—É–µ–º –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è (score = -inf)
        pool_valid = pool[pool["score"] != float('-inf')].copy()
        
        if pool_valid.empty:
            logger.warning(f"  ‚ö†Ô∏è –í—Å–µ –ø–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω—ã (–¥–æ—Å—Ç–∏–≥–ª–∏ –ª–∏–º–∏—Ç–∞), –æ—Å—Ç–∞–ª–æ—Å—å {remaining_to_allocate} —à—Ç.")
            break

        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ score –∏ –≤—ã–±–∏—Ä–∞–µ–º –ø–æ–±–µ–¥–∏—Ç–µ–ª—è
        pool_valid = pool_valid.sort_values("score", ascending=False)
        
        logger.debug(f"  üèÜ –¢–æ–ø-3 –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –ø–æ —Å–∫–æ—Ä—É:")
        for i, (_, row) in enumerate(pool_valid.head(3).iterrows(), 1):
            logger.debug(
                f"    #{i}: {row['department']} - score={row['score']:.2f}, velocity={row['weekly_velocity']:.2f}, coverage={row['coverage_weeks']:.1f}–Ω"
            )

        winner = pool_valid.iloc[0].copy()
        dept = winner["department"]
        cat = winner.get("category") or auction_meta.get(sku, {}).get("category")
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –≥–ª–æ–±–∞–ª—å–Ω—ã–π —Å—á–µ—Ç—á–∏–∫
        global_dept_load[dept] = global_dept_load.get(dept, 0) + 1
        
        meta = auction_meta.get(sku, {})
        loan = meta.get("loan") or 0
        price = meta.get("recommended_price") or meta.get("retail_price") or 0
        margin = max(price - loan, 0)

        cat = winner["category"] if pd.notna(winner["category"]) else auction_meta.get(sku, {}).get("category")
        cat = str(cat).strip()
        if cat and cat.lower() not in ("nan", "none", ""):
            # –û–±–Ω–æ–≤–ª—è–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤ –∫–∞—Ä—Ç–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–π
            if dept not in dept_cat_qty_map:
                dept_cat_qty_map[dept] = {}
            dept_cat_qty_map[dept][cat] = dept_cat_qty_map[dept].get(cat, 0) + 1

        base_vel = winner["weekly_velocity"]
        blend_vel = base_vel
        if cat:
            blend_vel += cfg.alpha_cat_velocity * cat_velocity.get((cat, dept), 0)
        blend_vel += cfg.alpha_dept_velocity * dept_velocity_map.get(dept, 0)

        prob_sell = predict_sell_probability(blend_vel, cfg.prob_target_days, cfg.velocity_prior)
        
        # –ü–æ–ª—É—á–∞–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
        meta_info = auction_meta.get(sku, {})
        item_name = meta_info.get("category", "")  # –í–∏–¥ –ø—Ä–µ–¥–º–µ—Ç–∞ = –∫–∞—Ç–µ–≥–æ—Ä–∏—è
        description = meta_info.get("description", "")  # –û–ø–∏—Å–∞–Ω–∏–µ
        
        reason = (
            f"—Å–∫–æ—Ä={winner['score']:.2f}, velocity={blend_vel:.2f}/–Ω–µ–¥, –ø–æ–∫—Ä—ã—Ç–∏–µ={winner['coverage_weeks']:.1f}–Ω, "
            f"p‚â§{cfg.prob_target_days}–¥‚âà{prob_sell*100:.1f}%, –º–∞—Ä–∂–∞‚âà{margin:.0f}"
        )
        
        logger.info(
            f"  ‚úÖ –®—Ç—É–∫–∞ {qty - remaining_to_allocate + 1}/{qty} ‚Üí {dept}: {reason}"
        )

        allocations.append(
            {
                "sku": sku,
                "department": dept,
                "region": winner.get("region"),  # –ò–°–ü–†–ê–í–õ–ï–ù–û: –∏—Å–ø–æ–ª—å–∑—É–µ–º –∏–∑ row
                "category": cat,
                "item_name": item_name,  # –ù–û–í–û–ï: –ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞
                "description": description,  # –ù–û–í–û–ï: –û–ø–∏—Å–∞–Ω–∏–µ
                "send_qty": 1,
                "stock_qty": winner.get("stock_qty", 0),
                "weekly_velocity": blend_vel,
                "coverage_weeks": winner.get("coverage_weeks", math.inf),
                "prob_sell": prob_sell,
                "score": winner.get("score", 0),
                "reason": reason,
            }
        )

        # –û–±–Ω–æ–≤–ª—è–µ–º –ø–æ–∫—Ä—ã—Ç–∏–µ –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ –ø–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è –ø–µ—Ä–µ–¥ —Å–ª–µ–¥—É—é—â–µ–π –∏—Ç–µ—Ä–∞—Ü–∏–µ–π.
        idx_update = pool.index[pool["department"] == dept][0]
        pool.at[idx_update, "stock_qty"] = winner["stock_qty"] + 1
        pool.at[idx_update, "coverage_weeks"] = (
            math.inf
            if winner["weekly_velocity"] <= 0
            else (winner["stock_qty"] + 1) / winner["weekly_velocity"]
        )
        remaining -= 1

    return allocations


def run_allocation(
    sales_path: Path,
    stock_path: Path,
    auction_path: Path,
    output_path: Path,
    auction_sku_column: Optional[str] = None,
    return_frames: bool = False,
    cfg: Optional[AllocationConfig | Dict[str, object]] = None,
):
    # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
    log_file = setup_logging()
    logger.info("\n" + "="*100)
    logger.info("üöÄ –ù–ê–ß–ê–õ–û –†–ê–°–ü–†–ï–î–ï–õ–ï–ù–ò–Ø –ê–£–ö–¶–ò–û–ù–ê")
    logger.info("="*100)
    
    sales = load_sales_table(sales_path)
    sku_velocity, dept_velocity, weeks_span = compute_velocity(sales)
    if not sales.empty:
        cat_velocity_series = sales.dropna(subset=["category"]).groupby(["category", "department"])["qty"].sum() / weeks_span
    else:
        cat_velocity_series = pd.Series(dtype=float)
    cat_velocity = cat_velocity_series.to_dict()
    dept_velocity_map = dept_velocity.set_index("department")["weekly_velocity"].to_dict()

    logger.info(f"–ü—Ä–æ–¥–∞–∂–∏ –∑–∞–≥—Ä—É–∂–µ–Ω—ã: {len(sales)} —Å—Ç—Ä–æ–∫, –æ–∫–Ω–æ {weeks_span} –Ω–µ–¥.")
    logger.info(f"–°–∫–æ—Ä–æ—Å—Ç—å –ø–æ SKU/–ø–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏—é: {len(sku_velocity)} –∑–∞–ø–∏—Å–µ–π.")
    logger.info(f"–°–∫–æ—Ä–æ—Å—Ç—å –ø–æ –ø–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏—é: {len(dept_velocity)} –∑–∞–ø–∏—Å–µ–π.")
    if not dept_velocity.empty:
        logger.info(f"–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ø–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏–π: {dept_velocity['department'].nunique()}")
        logger.info(f"–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Ä–µ–≥–∏–æ–Ω–æ–≤: {dept_velocity['region'].nunique()}")
    
    print(f"–ü—Ä–æ–¥–∞–∂–∏ –∑–∞–≥—Ä—É–∂–µ–Ω—ã: {len(sales)} —Å—Ç—Ä–æ–∫, –æ–∫–Ω–æ {weeks_span} –Ω–µ–¥.")
    print(f"–°–∫–æ—Ä–æ—Å—Ç—å –ø–æ SKU/–ø–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏—é: {len(sku_velocity)} –∑–∞–ø–∏—Å–µ–π.")
    print(f"–°–∫–æ—Ä–æ—Å—Ç—å –ø–æ –ø–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏—é: {len(dept_velocity)} –∑–∞–ø–∏—Å–µ–π.")

    stock = load_stock(stock_path)
    logger.info(f"–û—Å—Ç–∞—Ç–∫–∏ –∑–∞–≥—Ä—É–∂–µ–Ω—ã: {len(stock)} SKU-–ø–æ–∑–∏—Ü–∏–π.")
    print(f"–û—Å—Ç–∞—Ç–∫–∏ –∑–∞–≥—Ä—É–∂–µ–Ω—ã: {len(stock)} SKU-–ø–æ–∑–∏—Ü–∏–π.")

    coverage = build_coverage(stock, sku_velocity)
    auction_counts, auction_meta = load_auction(auction_path, auction_sku_column)
    logger.info(f"–õ–æ—Ç–æ–≤ –≤ —Ä–µ–µ—Å—Ç—Ä–µ: {sum(auction_counts.values())} (—É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö SKU: {len(auction_counts)}).")
    print(f"–õ–æ—Ç–æ–≤ –≤ —Ä–µ–µ—Å—Ç—Ä–µ: {sum(auction_counts.values())} (—É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö SKU: {len(auction_counts)}).")

    if cfg is None:
        config = AllocationConfig()
    elif isinstance(cfg, dict):
        config = AllocationConfig(**cfg)
    else:
        config = cfg
    
    # üÜï –°–¢–†–û–ò–ú –ö–ê–†–¢–£ –ö–û–õ–ò–ß–ï–°–¢–í–ê –ü–û –ö–ê–¢–ï–ì–û–†–ò–Ø–ú (–¥–ª—è Assortment Balance)
    # dept -> category -> count
    dept_cat_qty_map: Dict[str, Dict[str, int]] = {}
    
    # 1. –ó–∞–ø–æ–ª–Ω—è–µ–º –∏–∑ —Ç–µ–∫—É—â–∏—Ö –æ—Å—Ç–∞—Ç–∫–æ–≤
    if stock is not None and not stock.empty:
        # stock –¥–æ–ª–∂–µ–Ω –∏–º–µ—Ç—å –∫–æ–ª–æ–Ω–∫–∏ department, category, stock_qty
        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º, —á—Ç–æ–±—ã –ø–æ–ª—É—á–∏—Ç—å —Å—É–º–º—É —à—Ç—É–∫ –ø–æ (–ø–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ, –∫–∞—Ç–µ–≥–æ—Ä–∏—è)
        stock_grp = stock.groupby(["department", "category"])["stock_qty"].sum().reset_index()
        for _, row in stock_grp.iterrows():
            d = row["department"]
            c = str(row["category"]).strip()
            q = int(row["stock_qty"])
            if d not in dept_cat_qty_map:
                dept_cat_qty_map[d] = {}
            dept_cat_qty_map[d][c] = dept_cat_qty_map[d].get(c, 0) + q

    allocations: List[Dict[str, object]] = []
    # 1. –°—á–∏—Ç—ã–≤–∞–µ–º —Ä–µ–µ—Å—Ç—Ä
    auction_counts, auction_meta = load_auction(auction_path, auction_sku_column)
    logger.info(f"–õ–æ—Ç–æ–≤ –≤ —Ä–µ–µ—Å—Ç—Ä–µ: {sum(auction_counts.values())} (—É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö SKU: {len(auction_meta)}).")
    
    # üö® –†–ê–°–ß–ï–¢ –û–ë–©–ï–ì–û –õ–ò–ú–ò–¢–ê
    total_items = sum(auction_counts.values())
    max_per_dept_global = int(total_items * config.max_department_percentage) if config.max_department_percentage else None
    if max_per_dept_global:
        logger.info(f"üéØ –ì–õ–û–ë–ê–õ–¨–ù–´–ô –õ–ò–ú–ò–¢ –Ω–∞ –ø–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ: {max_per_dept_global} —à—Ç ({config.max_department_percentage*100:.0f}% –æ—Ç {total_items})")
    
    # –û–±—â–∏–π —Å—á–µ—Ç—á–∏–∫ –∑–∞–≥—Ä—É–∑–∫–∏ –ø–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏–π
    global_dept_load: Dict[str, int] = {}

    
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º SKU: —Å–Ω–∞—á–∞–ª–∞ —Ä–µ–¥–∫–∏–µ/–¥–æ—Ä–æ–≥–∏–µ (–ø–æ –∂–µ–ª–∞–Ω–∏—é), –∏–ª–∏ –ø—Ä–æ—Å—Ç–æ –∏–¥–µ–º –ø–æ —Å–ø–∏—Å–∫—É
    # –°–µ–π—á–∞—Å –∏–¥–µ–º –ø—Ä–æ—Å—Ç–æ –ø–æ –ø–æ—Ä—è–¥–∫—É –∫–ª—é—á–µ–π
    for sku, qty in auction_counts.items():
        allocate_sku(
            sku,
            qty,
            coverage,
            dept_velocity,
            cat_velocity,
            dept_velocity_map,
            auction_meta,
            allocations, # –ù–û–í–û–ï: –ø–µ—Ä–µ–¥–∞–µ–º —Å–ø–∏—Å–æ–∫
            dept_cat_qty_map, # –ù–û–í–û–ï: –∫–∞—Ä—Ç–∞ –∫–æ–ª–∏—á–µ—Å—Ç–≤
            config,
            stock=stock,
            global_dept_load=global_dept_load,
            max_per_dept_global=max_per_dept_global
        )

    # –°–æ–±–∏—Ä–∞–µ–º –∏—Ç–æ–≥–æ–≤—ã–π DataFrame

    # –°–æ–±–∏—Ä–∞–µ–º –∏—Ç–æ–≥–æ–≤—ã–π DataFrame

    if not allocations:
        logger.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ ‚Äî –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö –ø–æ –ø—Ä–æ–¥–∞–∂–∞–º/–æ—Å—Ç–∞—Ç–∫–∞–º.")
        raise RuntimeError("–ù–µ —É–¥–∞–ª–æ—Å—å —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ ‚Äî –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö –ø–æ –ø—Ä–æ–¥–∞–∂–∞–º/–æ—Å—Ç–∞—Ç–∫–∞–º.")

    alloc_df = pd.DataFrame(allocations)
    alloc_df = alloc_df.rename(
        columns={
            "sku": "–ê—Ä—Ç–∏–∫—É–ª",
            "department": "–ü–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ",
            "region": "–†–µ–≥–∏–æ–Ω",
            "category": "–ö–∞—Ç–µ–≥–æ—Ä–∏—è",
            "item_name": "–í–∏–¥ –ø—Ä–µ–¥–º–µ—Ç–∞",  # –ù–û–í–û–ï
            "description": "–û–ø–∏—Å–∞–Ω–∏–µ",  # –ù–û–í–û–ï
            "send_qty": "–û—Ç–ø—Ä–∞–≤–∏—Ç—å, —à—Ç",
            "stock_qty": "–¢–µ–∫—É—â–∏–π –æ—Å—Ç–∞—Ç–æ–∫, —à—Ç",
            "weekly_velocity": "–°–∫–æ—Ä–æ—Å—Ç—å, —à—Ç/–Ω–µ–¥",
            "coverage_weeks": "–ü–æ–∫—Ä—ã—Ç–∏–µ, –Ω–µ–¥–µ–ª—å",
            "prob_sell": f"–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –ø—Ä–æ–¥–∞–∂–∏ ‚â§{config.prob_target_days}–¥, %",
            "score": "–°–∫–æ—Ä",
            "reason": "–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π",
        }
    )
    alloc_df[f"–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –ø—Ä–æ–¥–∞–∂–∏ ‚â§{config.prob_target_days}–¥, %"] = (
        alloc_df[f"–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –ø—Ä–æ–¥–∞–∂–∏ ‚â§{config.prob_target_days}–¥, %"] * 100
    )

    summary_df = (
        alloc_df.groupby(["–ü–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ", "–†–µ–≥–∏–æ–Ω"], as_index=False)["–û—Ç–ø—Ä–∞–≤–∏—Ç—å, —à—Ç"]
        .sum()
        .sort_values("–û—Ç–ø—Ä–∞–≤–∏—Ç—å, —à—Ç", ascending=False)
    )

    output_path.parent.mkdir(parents=True, exist_ok=True)
    with pd.ExcelWriter(output_path) as writer:
        alloc_df.to_excel(writer, sheet_name="–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ", index=False)
        summary_df.to_excel(writer, sheet_name="–ò—Ç–æ–≥ –ø–æ –ø–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è–º", index=False)

    logger.info("\n" + "="*100)
    logger.info("üìä –ò–¢–û–ì–û–í–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê")
    logger.info("="*100)
    logger.info(f"–í—Å–µ–≥–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–æ: {len(allocations)} —à—Ç—É–∫")
    logger.info(f"–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö SKU: {alloc_df['–ê—Ä—Ç–∏–∫—É–ª'].nunique()}")
    logger.info(f"–ü–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏–π –∑–∞–¥–µ–π—Å—Ç–≤–æ–≤–∞–Ω–æ: {len(summary_df)}")
    logger.info("\n–¢–æ–ø-5 –ø–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏–π –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É:")
    for idx, row in summary_df.head(5).iterrows():
        pct = row['–û—Ç–ø—Ä–∞–≤–∏—Ç—å, —à—Ç'] / sum(summary_df['–û—Ç–ø—Ä–∞–≤–∏—Ç—å, —à—Ç']) * 100
        logger.info(f"  {idx+1}. {row['–ü–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ']} ({row['–†–µ–≥–∏–æ–Ω']}): {row['–û—Ç–ø—Ä–∞–≤–∏—Ç—å, —à—Ç']} —à—Ç ({pct:.1f}%)")
    logger.info(f"\n‚úÖ –§–∞–π–ª —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {output_path}")
    logger.info(f"üìù –õ–æ–≥ —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {log_file}")
    logger.info("="*100 + "\n")
    
    print(f"–§–∞–π–ª —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {output_path}")
    print(f"üìù –õ–æ–≥ —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {log_file}")
    if return_frames:
        return output_path, alloc_df, summary_df
    return output_path


def parse_args() -> argparse.Namespace:
    default_sales = BASE_DIR / "–¢–∞–±–ª–∏—á–Ω–∞—è_—á–∞—Å—Ç—å_–ü—Ä–æ–¥–∞–∂–∏_—Ä–∞—Å–ø—Ä–æ–¥–∞–∂–∞_0109_311225.xlsx"
    default_stock = BASE_DIR / "–æ—Å—Ç–∞—Ç–∫–∏ –Ω–∞ 301125.xlsx"
    default_auction = BASE_DIR / "–†–µ–µ—Å—Ç—Ä –∞—É–∫—Ü–∏–æ–Ω–∞ 15.11 –°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥.xlsx"
    default_output = BASE_DIR / "—Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ_–∞—É–∫—Ü–∏–æ–Ω.xlsx"

    parser = argparse.ArgumentParser(description="–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ª–æ—Ç–æ–≤ –∞—É–∫—Ü–∏–æ–Ω–∞ –ø–æ –ø–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è–º.")
    parser.add_argument("--sales", type=Path, default=default_sales, help="–ü—É—Ç—å –∫ —Ñ–∞–π–ª—É —Ç–∞–±–ª–∏—á–Ω–æ–π —á–∞—Å—Ç–∏ –ø—Ä–æ–¥–∞–∂.")
    parser.add_argument("--stock", type=Path, default=default_stock, help="–ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –æ—Å—Ç–∞—Ç–∫–æ–≤.")
    parser.add_argument("--auction", type=Path, default=default_auction, help="–ü—É—Ç—å –∫ —Ä–µ–µ—Å—Ç—Ä—É –∞—É–∫—Ü–∏–æ–Ω–∞.")
    parser.add_argument("--out", type=Path, default=default_output, help="–ü—É—Ç—å –∫ –∏—Ç–æ–≥–æ–≤–æ–º—É XLSX.")
    parser.add_argument(
        "--auction-sku-column",
        type=str,
        default=None,
        help="–ï—Å–ª–∏ –∏–º—è –∫–æ–ª–æ–Ω–∫–∏ —Å –∞—Ä—Ç–∏–∫—É–ª–æ–º –≤ —Ä–µ–µ—Å—Ç—Ä–µ –¥—Ä—É–≥–æ–µ, —É–∫–∞–∂–∏—Ç–µ –µ–≥–æ –∑–¥–µ—Å—å.",
    )
    return parser.parse_args()


if __name__ == "__main__":
    args = parse_args()
    run_allocation(args.sales, args.stock, args.auction, args.out, args.auction_sku_column)
